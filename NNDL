# Import libraries
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv1D, LSTM, Flatten, Dropout, MaxPooling1D
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# 1. Load and preprocess the data
# Simulated dataset with columns: ['temperature', 'humidity', 'pressure', 'wind_speed']
def load_data():
    # Replace with your own dataset path
    data = pd.read_csv("weather_data.csv")
    return data

# Scale features to [0,1] range
def preprocess_data(data):
    scaler = MinMaxScaler(feature_range=(0, 1))
    scaled_data = scaler.fit_transform(data)
    return scaled_data, scaler

# Create sequences for hybrid model
def create_sequences(data, sequence_length):
    X, y = [], []
    for i in range(len(data) - sequence_length):
        X.append(data[i:i+sequence_length])
        y.append(data[i+sequence_length, 0])  # Predicting temperature (1st column)
    return np.array(X), np.array(y)

# 2. Load data
sequence_length = 10  # Time steps
data = load_data()
scaled_data, scaler = preprocess_data(data)

# Split into sequences
X, y = create_sequences(scaled_data, sequence_length)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Reshape for CNN input (samples, time steps, features)
input_shape = (X_train.shape[1], X_train.shape[2])

# 3. Build the hybrid CNN-LSTM model
model = Sequential()

# CNN for feature extraction
model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=input_shape))
model.add(MaxPooling1D(pool_size=2))
model.add(Dropout(0.2))

# LSTM for temporal modeling
model.add(LSTM(50, activation='tanh', return_sequences=False))
model.add(Dropout(0.2))

# Fully connected layer
model.add(Dense(25, activation='relu'))
model.add(Dense(1))  # Output layer (predicting 1 value, e.g., temperature)

# 4. Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# 5. Train the model
history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=1)

# 6. Evaluate the model
loss = model.evaluate(X_test, y_test)
print(f"Test Loss: {loss}")

# 7. Predict and inverse transform
predictions = model.predict(X_test)
predictions = scaler.inverse_transform(np.concatenate((predictions, np.zeros((predictions.shape[0], scaled_data.shape[1] - 1))), axis=1))[:, 0]

# Actual values
y_test_actual = scaler.inverse_transform(np.concatenate((y_test.reshape(-1, 1), np.zeros((y_test.shape[0], scaled_data.shape[1] - 1))), axis=1))[:, 0]

# 8. Plot results
plt.figure(figsize=(10, 6))
plt.plot(y_test_actual, label='Actual Temperature')
plt.plot(predictions, label='Predicted Temperature')
plt.legend()
plt.title("Temperature Forecasting: Actual vs Predicted")
plt.xlabel("Samples")
plt.ylabel("Temperature")
plt.show()
